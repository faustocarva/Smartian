import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import f_oneway
import matplotlib.cm as cm
from matplotlib.colors import to_rgba


class DataCollect():
    LLAMA3_70_COLOR = '#1f77b4'
    LLAMA3_8_COLOR = '#ff7f0e'
    GPTOMINI_COLOR = '#2ca02c'
    MIXTRAL_8X7B_COLOR = '#d62728'
    METRICS_HEADER = 'model,temperature,file,total_files,total_files_with_invalid_json,total_seeds,total_duplicate_seeds,total_seeds_with_invalid_struct,total_args_in_seeds,total_invalid_args_in_seeds,total_functions_in_seeds,total_invalid_function_in_seeds'.split(',')
    COVERAGE_HEADER = 'contract,temperature,transaction_index,model,seed_file,totalExecutions,deployFailCount,coveredEdges,coveredInstructions,coveredDefUseChains,bugsFound'.split(',')
    
    def __init__(self) -> None:
        print("")
    
    def total_seeds(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)
                
        max_total_seeds = df['total_seeds'].max()                
        result = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'mean_seeds': round(group['total_seeds'].mean())
            }))
            .reset_index()            
        )        
        plt.figure(figsize=(10, 6))

        for model in result['model'].unique():
            model_data = result[result['model'] == model]
            plt.plot(
                model_data['temperature'],
                model_data['mean_seeds'],
                label=f'{model}',
                marker='o',  # Add markers at each point
                linestyle='-',  # Solid line
                linewidth=2
            )

        # Labels and title
        plt.title('Mean total seeds generated by Model per Temperature', fontsize=16)
        plt.xlabel('Temperature', fontsize=14)
        plt.ylabel('Total seeds', fontsize=14)
        
        plt.ylim(0, max_total_seeds)        
        plt.xlim(0.0, 1.2)
        plt.grid(alpha=0.3)
        plt.legend(fontsize=12, loc='best')

        plt.tight_layout()
        plt.savefig('plot_total_seeds_by_model_temperature.png', dpi=800)        
                
        ########################################################################################################
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']         
        df['valid_seeds'] = df['valid_seeds'].replace(0, pd.NA)
        
        result_by_model_temp = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'mean_seeds': round(group['valid_seeds'].mean())
            }))
            .reset_index()
        )
        
        result_by_model = (
            df.groupby(['model'])
            .apply(lambda group: pd.Series({
                'mean_seeds': round(group['valid_seeds'].mean())
            }))
            .reset_index()
        )
        result_by_model = result_by_model.sort_values(by=['mean_seeds'], ascending=False)
        print(result_by_model)

        plt.figure(figsize=(10, 6))

        line_data = {}
        for model in result_by_model_temp['model'].unique():
            model_data_temp = result_by_model_temp[result_by_model_temp['model'] == model]
            line, =  plt.plot(
                model_data_temp['temperature'],
                model_data_temp['mean_seeds'],
                label=f'{model}',
                marker='o',
                linestyle='-',  # Solid line
                linewidth=2,
            )
            line_data[model] = {
                'line': line,
                'color': line.get_color()
            }

        # Plot data grouped by model only
        for model in result_by_model['model']:
            mean_seed = result_by_model[result_by_model['model'] == model]['mean_seeds'].values[0]
            plt.axhline(
                y=mean_seed,
                linestyle='--',
                color=line_data[model]['color']  
            )

        # Labels and title
        plt.title('Valid Generated Seeds per Model & Temperature', fontsize=16)
        plt.xlabel('Temperature', fontsize=14)
        plt.ylabel('Total Seeds', fontsize=14)
        
        plt.ylim(0, max_total_seeds)
        plt.xlim(0.0, 1.2)
        plt.grid(alpha=0.3)
        plt.legend(fontsize=10, loc='best')

        # Show plot
        plt.tight_layout()                
        
        plt.savefig('plot_total_efective_seeds_by_model_temperature.png', dpi=800)
         
    def duplicate_print_tables(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)

        # Find the global maximum value of total_seeds
        #max_total_seeds = 580
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']         
        df['valid_seeds'] = df['valid_seeds'].replace(0, pd.NA)

        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['invalid_struct_percentage'] = (df['total_seeds_with_invalid_struct'] / max_total_seeds) * 100
        
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)
        df['invalid_struct_rate'] = df['total_seeds_with_invalid_struct'] / max_total_seeds

        df['penalty_factor'] = (1 - df['duplicate_rate'] - df['invalid_struct_rate']).clip(lower=0)
        df['performance_score'] = df['total_seeds'] * df['penalty_factor']
        

        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )
        
        result = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'duplicate_percentage': group['duplicate_percentage'].mean(),
                'invalid_struct_percentage': group['invalid_struct_percentage'].mean(),                
                'performance_score': group['normalized_performance_score'].mean(),
                'mean_valid_seeds': round(group['valid_seeds'].mean()),
                'mean_total_seeds': round(group['total_seeds'].mean())                
            }))
            .reset_index()            
        )        

        result_model = (
            df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'duplicate_percentage': group['duplicate_percentage'].mean(),
                'invalid_struct_percentage': group['invalid_struct_percentage'].mean(),                                
                'performance_score': group['normalized_performance_score'].mean(),
                'mean_valid_seeds': round(group['valid_seeds'].mean()),
                'mean_total_seeds': round(group['total_seeds'].mean())                                
            }))
            .reset_index()            
        )        
        
        result['uniq_percentage'] = 100 - result["duplicate_percentage"]
        result_model['uniq_percentage'] = 100 - result["duplicate_percentage"]        
        
        result = result.sort_values(by=['performance_score'], ascending=False)
        print(result)
        
        print("================================================================================================")
        
        result_model= result_model.sort_values(by=['performance_score'], ascending=False)
        print(result_model)
        
        print("================================================================================================")
        
        latex_table = result_model.to_latex(index=False)
        print(latex_table)
        print("================================================================================================")                     

    def duplicate_graph_dual(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']         
        #max_total_seeds = 580

        # Normalize the total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])
        
        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )
        
        result = (
            df.groupby(['model', 'temperature'])
            #df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'duplicate_percentage': group['duplicate_percentage'].mean(),
                'performance_score': group['normalized_performance_score'].mean(),
                'mean_seeds': round(group['total_seeds'].mean())  # Calculate mean number of seeds
            }))
            .reset_index()            
        )        

        result_model = (
            df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'duplicate_percentage': group['duplicate_percentage'].mean(),
                'performance_score': group['normalized_performance_score'].mean(),
                'mean_seeds': round(group['total_seeds'].mean())  # Calculate mean number of seeds
            }))
            .reset_index()            
        )        

        
        result['uniq_percentage'] = 100 - result["duplicate_percentage"]
        result_model['uniq_percentage'] = 100 - result["duplicate_percentage"]        
        
        result = result.sort_values(by=['performance_score'], ascending=False)
        
        result = result.sort_values(by=['model', 'temperature'], ascending=False)        
        plt.figure(figsize=(10, 6))

        # Create a dual-axis plot
        fig, ax1 = plt.subplots(figsize=(10, 6))

        # Plot performance score on the primary axis
        for model in result['model'].unique():
            model_data = result[result['model'] == model]
            ax1.plot(
                model_data['temperature'],
                model_data['performance_score'],
                #model_data['duplicate_percentage'],
                label=f'Model {model}',
                marker='o',  # Add markers at each point
                linestyle='-',  # Solid line
                linewidth=2
            )

        ax1.set_xlabel('Temperature', fontsize=14)
        ax1.set_ylabel('Seed unique ratio (%)', fontsize=14, color='blue')
        ax1.set_xlim(0.0, 1.2)
        ax1.set_ylim(0, 100)
        ax1.grid(alpha=0.3)

        # Secondary y-axis for mean seeds
        ax2 = ax1.twinx()
        for model in result['model'].unique():
            model_data = result[result['model'] == model]
            ax2.plot(
                model_data['temperature'],
                model_data['mean_seeds'],
                #label=f'{model} Total Seeds',
                marker='x',  # Add different markers
                linestyle='--',  # Dashed line
                linewidth=2
            )

        ax2.set_ylabel('Total Seeds', fontsize=14, color='orange')
        ax2.set_ylim(0, result['mean_seeds'].max() + 10)

        # Combine legends for both axes
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=12)

        # Add title
        plt.title('Seed unique ratio and Total Seeds vs Temperature', fontsize=16)

        # Save and show the plot
        plt.tight_layout()
        plt.savefig('line_plote_perf_score_dual_axis.png', dpi=600)

    def duplicate_graph_simple(self, csv):
        df = pd.read_csv(csv)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']         
        #max_total_seeds = 580

        # Normalize the total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])
        
        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )
        
        result = (
            df.groupby(['model', 'temperature'])
            #df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'duplicate_percentage': group['duplicate_percentage'].mean(),
                'performance_score': group['normalized_performance_score'].mean(),
                'mean_seeds': round(group['total_seeds'].mean())  # Calculate mean number of seeds
            }))
            .reset_index()            
        )        
               
        # Round values
        result['duplicate_percentage'] = result['duplicate_percentage'].round(2)
        result['performance_score'] = result['performance_score'].round(2)
        result['mean_seeds'] = result['mean_seeds'].round(2)

        # Line Plot
        plt.figure(figsize=(10, 6))

        # Plot each model's grouped data
        for model in result['model'].unique():
            model_data = result[result['model'] == model]
            plt.plot(
                model_data['temperature'],
                model_data['performance_score'],
                label=f'Model {model}',
                marker='o',  # Add markers at each point
                linestyle='-',  # Solid line
                linewidth=2
            )

        # Labels and title
        plt.title('Seed unique/capacity generation ratio vs Temperature', fontsize=16)
        plt.xlabel('Temperature', fontsize=14)
        plt.ylabel('Seed unique/capacity generation ratio (%)', fontsize=14)
        plt.xlim(0.0, 1.2)
        plt.ylim(0, 100)
        plt.grid(alpha=0.3)
        plt.legend(fontsize=12, loc='best')

        # Show plot
        plt.tight_layout()
        plt.savefig('line_plot_perf.png', dpi=300)
        
    def duplicate_cluster_quality_simple(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']

        # Normalize the total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])
        
        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )

        # Calculate the performance metrics
        max_total_seeds = df['total_seeds'].max()

        # Normalize total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        # Calculate performance score
        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])

        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )

        # Aggregate data by model and temperature
        result = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'performance_score': group['normalized_performance_score'].mean()
            }))
            .reset_index()
        )

        # Sort the results by performance score
        result = result.sort_values(by=['performance_score'], ascending=False)

        # Prepare the data for visualization
        models = result['model'].unique()

        # Sort temperatures in ascending order for each model
        temperatures = sorted(result['temperature'].unique())

        # Prepare the data for each model and temperature (ordered by temperature)
        performance_score_values = []

        for model in models:
            performance_score_row = []
            for temp in temperatures:
                row = result[(result['model'] == model) & (result['temperature'] == temp)]
                if not row.empty:
                    performance_score_row.append(row['performance_score'].values[0])
            performance_score_values.append(performance_score_row)

        # Set the x locations for the groups (models), with added space between each model
        x = np.arange(len(models)) * 3  # Multiply by 3 to increase space between each cluster
        width = 0.3  # The width of the bars

        # Create the figure
        fig, ax = plt.subplots(figsize=(14, 8))

        model_colors = {
            "Llama3-70B": "#1f77b4",
            "Llama3-8B": "#ff7f0e",
            "gpt4omini": "#2ca02c",
            "mixtral-8x7b": "#d62728"
        }

        # Plot bars for Performance Score
        for j, model in enumerate(models):
            base_color = to_rgba(model_colors.get(model, "#7f7f7f"))  # Default to gray if model color is missing

            for i, temp in enumerate(temperatures):
                # Adjust color intensity for the temperatures
                base_intensity = 0.7
                variation_range = 0.2
                color_intensity = base_intensity + variation_range * (i / (len(temperatures) - 1))
                adjusted_color = (base_color[0] * color_intensity, 
                                base_color[1] * color_intensity, 
                                base_color[2] * color_intensity, 
                                base_color[3])  # Maintain alpha

                # Plot Performance Score
                ax.bar(x[j] + i * width, performance_score_values[j][i], width, color=adjusted_color)

                # Add the temperature label below the bars
                ax.text(
                    x[j] + i * width,
                    -1,  # Position below the x-axis
                    f"{temp}",
                    ha="center",
                    va="top",
                    rotation=90,
                    fontsize=10,
                )

        # Customize the chart
        ax.set_ylabel("Seed Quality Score (%)")  # Updated label to indicate percentage
        ax.set_title("Seed Quality Score per Model and Temperature")

        # Set the x-axis ticks to be in the center of each cluster
        ax.set_xticks(x + width * (len(temperatures) - 1) / 2)
        ax.set_xticklabels([])  # Remove x-axis tick labels

        # Add legend for models
        ax.legend(
            [plt.Rectangle((0, 0), 1, 1, color=model_colors[model]) for model in models],
            models,
            title="Models",
        )

        # Adjust margins to create more space for the temperature labels
        plt.subplots_adjust(bottom=0.1)  # Increase bottom margin

        # Set the y-axis to be in percentage
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0f}%'))  # Format y-axis as percentage
                   
        # Display the plot
        plt.tight_layout()

        plt.savefig('bar_cluster_quality_score.png', dpi=600)
        
    def duplicate_cluster_quality_temp(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']

        # Normalize the total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])
        
        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )
        
        # Calculate the performance metrics
        max_total_seeds = df['total_seeds'].max()

        # Normalize total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        # Calculate performance score
        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])

        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )

        # Aggregate data by model and temperature
        result = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'performance_score': group['normalized_performance_score'].mean()
            }))
            .reset_index()
        )

        # Sort the results by performance score
        result = result.sort_values(by=['performance_score'], ascending=False)

        # Prepare the data for visualization
        models = result['model'].unique()

        # Sort temperatures in ascending order for each model
        temperatures = sorted(result['temperature'].unique())

        # Prepare the data for each model and temperature (ordered by temperature)
        performance_score_values = []

        for temp in temperatures:
            performance_score_row = []
            for model in models:
                row = result[(result['model'] == model) & (result['temperature'] == temp)]
                if not row.empty:
                    performance_score_row.append(row['performance_score'].values[0])
                else:
                    performance_score_row.append(0)  # If no data for a model-temperature pair
            performance_score_values.append(performance_score_row)

        # Set the x locations for the groups (temperatures), with added space between each temperature
        x = np.arange(len(temperatures)) * 3  # Multiply by 3 to increase space between each cluster
        width = 0.5  # The width of the bars

        # Create the figure
        fig, ax = plt.subplots(figsize=(14, 8))

        model_colors = {
            "Llama3-70B": "#1f77b4",
            "Llama3-8B": "#ff7f0e",
            "gpt4omini": "#2ca02c",
            "mixtral-8x7b": "#d62728"
        }

        # Plot bars for Performance Score
        for i, temp in enumerate(temperatures):
            for j, model in enumerate(models):
                # Adjust color intensity for the models
                base_color = to_rgba(model_colors.get(model, "#7f7f7f"))  # Default to gray if model color is missing

                # Adjust color intensity for the models
                base_intensity = 0.7
                variation_range = 0.2
                color_intensity = base_intensity + variation_range * (j / (len(models) - 1))
                adjusted_color = (base_color[0] * color_intensity, 
                                base_color[1] * color_intensity, 
                                base_color[2] * color_intensity, 
                                base_color[3])  # Maintain alpha

                # Plot Performance Score
                ax.bar(x[i] + j * width, performance_score_values[i][j], width, color=adjusted_color)

                # Add the model label below the bars
                ax.text(
                    x[i] + j * width,
                    -1,  # Position below the x-axis
                    f"{model}",
                    ha="center",
                    va="top",
                    rotation=90,
                    fontsize=10,
                )

        # Customize the chart
        ax.set_ylabel("Seed Quality Score (%)")  # Updated label to indicate percentage
        ax.set_title("Seed Quality Score per Temperature and Model")

        # Set the x-axis ticks to be in the center of each cluster
        ax.set_xticks(x + width * (len(models) - 1) / 2)
        ax.set_xticklabels(temperatures)  # Set x-axis tick labels to temperatures

        # Adjust margins to create more space for the model labels
        plt.subplots_adjust(bottom=0.2)  # Increase bottom margin

        # Set the y-axis to be in percentage
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0f}%'))  # Format y-axis as percentage

        # Display the plot
        plt.tight_layout()
        
        plt.savefig('bar_cluster_quality_score_2.png', dpi=600)      
        
    def duplicate_cluster_quality_heat(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        
        df['valid_seeds'] = df['total_seeds'] - df['total_duplicate_seeds'] - df['total_seeds_with_invalid_struct']

        # Normalize the total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])
        
        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )
                
        max_total_seeds = df['total_seeds'].max()

        # Normalize total_duplicate_seeds and total_seeds by the global max
        df['duplicate_percentage'] = (df['total_duplicate_seeds'] / max_total_seeds) * 100
        df['duplicate_rate'] = (df['total_duplicate_seeds'] / max_total_seeds)

        # Calculate performance score
        df['performance_score'] = df['total_seeds'] * (1 - df['duplicate_rate'])

        # Normalize Performance Score to 0-100
        min_score = df['performance_score'].min()
        max_score = df['performance_score'].max()
        df['normalized_performance_score'] = (
            (df['performance_score'] - min_score) / (max_score - min_score) * 100
        )

        # Aggregate data by model and temperature
        result = (
            df.groupby(['model', 'temperature'])
            .apply(lambda group: pd.Series({
                'performance_score': group['normalized_performance_score'].mean()
            }))
            .reset_index()
        )

        # Calculate the mean performance score for each model
        model_performance = result.groupby('model')['performance_score'].mean().reset_index()

        # Sort the models based on the mean performance score in descending order
        sorted_models = model_performance.sort_values(by='performance_score', ascending=False)['model']

        # Reorder the result DataFrame based on the sorted models
        result['model'] = pd.Categorical(result['model'], categories=sorted_models, ordered=True)

        # Pivot the data to create a matrix where rows are models and columns are temperatures
        heatmap_data = result.pivot(index='model', columns='temperature', values='performance_score')

        # Create a heatmap with Reds colormap
        plt.figure(figsize=(14, 8))

        # Use Seaborn's heatmap function with Reds colormap
        sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', fmt='.1f', linewidths=0.9)

        # Customize the plot
        plt.title('Normalized Seed Quality Score per Model and Temperature', fontsize=16)
        plt.xlabel('Temperature', fontsize=14)
        plt.ylabel('Model', fontsize=14)

        # Make y-axis labels horizontal and increase font size
        plt.yticks(rotation=0, fontsize=12)  # Set horizontal y labels with bigger font size

        # Show the plot
        plt.tight_layout()

        plt.savefig('bar_cluster_quality_score_3.png', dpi=600)      
                  
    def metrics_info(self, csv):
        df = pd.read_csv(csv, header=None, names=self.METRICS_HEADER)
        
        grouped = (
            #df.groupby(['model', 'temperature'])
            df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'mean_seeds': group['total_seeds'].mean(),
                'mean_duplicate_seeds': group['total_duplicate_seeds'].mean(),
                'mean_seeds_with_invalid_struct': group['total_seeds_with_invalid_struct'].mean(),
                'mean_args_in_seeds': (group['total_args_in_seeds'].mean()),
                'mean_invalid_args_in_seeds': (group['total_invalid_args_in_seeds'].mean()),
                'mean_functions_in_seeds': (group['total_functions_in_seeds'].mean()),
                'mean_invalid_function_in_seeds': (group['total_invalid_function_in_seeds'].mean()),
                
            }))
            .reset_index()
        )
        
        grouped = grouped.sort_values(by=['mean_seeds', 'mean_duplicate_seeds', 'mean_seeds_with_invalid_struct'], ascending=False)
        pd.set_option('display.max_columns', None)  # Show all columns
        pd.set_option('display.width', 1000)       # Increase display width for better formatting

        # Print the result
        print(grouped)        
        
    
    def valid(self, csv):
        df = pd.read_csv(csv)

        # Find the global maximum value of total_seeds
        max_total_seeds = df['total_seeds'].max()
        max_total_args_in_seeds = df['total_args_in_seeds'].max()
        max_total_functions_in_seeds = df['total_functions_in_seeds'].max()
        print(max_total_args_in_seeds,max_total_functions_in_seeds,max_total_seeds)
        
        df['invalid_args_in_seeds'] = (df['total_invalid_args_in_seeds'] / max_total_args_in_seeds) * 100
        df['invalid_functions_in_seeds'] = (df['total_invalid_function_in_seeds'] / max_total_functions_in_seeds) * 100

        result = (
            df.groupby(['model', 'temperature'])
            #df.groupby(['model'])            
            .apply(lambda group: pd.Series({
                'invalid_args_in_seeds': group['invalid_args_in_seeds'].mean(),
                'invalid_functions_in_seeds': group['invalid_functions_in_seeds'].mean(),
            }))
            .reset_index()            
        )        
        
        result = result.sort_values(by=['model', 'temperature'], ascending=False)
        print(result)

    def coverage(self, csv):
        df = pd.read_csv(csv, header=None, names=self.COVERAGE_HEADER)
        
        
        df[['totalExecutions','deployFailCount','coveredEdges','coveredInstructions','coveredDefUseChains','bugsFound']] = df[['totalExecutions','deployFailCount','coveredEdges','coveredInstructions','coveredDefUseChains','bugsFound']].fillna(0)
        
        average_covered_instructions = df.groupby(['model', 'temperature'])['coveredInstructions'].mean().reset_index()
        average_covered_instructions.rename(columns={'coveredInstructions': 'averageCoveredInstructions'}, inplace=True)
        average_covered_instructions = average_covered_instructions.sort_values(by=['averageCoveredInstructions'], ascending=False)
        print(average_covered_instructions)

        average_covered_edges = df.groupby(['model', 'temperature'])['coveredEdges'].mean().reset_index()
        average_covered_edges.rename(columns={'coveredEdges': 'averageCoveredEdges'}, inplace=True)
        average_covered_edges = average_covered_edges.sort_values(by=['averageCoveredEdges'], ascending=False)
        print(average_covered_edges)
        
        average_defusechain = df.groupby(['model', 'temperature'])['coveredDefUseChains'].mean().reset_index()
        average_defusechain.rename(columns={'coveredDefUseChains': 'averageCoveredDefUseChains'}, inplace=True)
        average_defusechain = average_defusechain.sort_values(by=['averageCoveredDefUseChains'], ascending=False)
        print(average_defusechain)
        
        average_bugsfound = df.groupby(['model', 'temperature'])['bugsFound'].mean().reset_index()
        average_bugsfound.rename(columns={'bugsFound': 'averageBugsFound'}, inplace=True)
        average_bugsfound = average_bugsfound.sort_values(by=['averageBugsFound'], ascending=False)
        print(average_bugsfound)

        #total_fail = df.groupby(['model'])['deployFailCount'].mean().reset_index()
        total_fail = df.groupby(['model']).size().reset_index()
        print(total_fail)
        # total_fail.rename(columns={'deployFailCount': 'totaldeployFailCount'}, inplace=True)
        # total_fail = total_fail.sort_values(by=['totaldeployFailCount'], ascending=False)
        # print(total_fail)


        total_seeds_per_model = df.groupby('model')['seed_file'].count()
        print(total_seeds_per_model)
        # Find the model with the most seeds
        max_seeds = total_seeds_per_model.max()

        # Normalize the data based on the model with the most seeds
        df['normalizedCoveredEdges'] = df['coveredEdges'] / max_seeds
        df['normalizedCoveredInstructions'] = df['coveredInstructions'] / max_seeds
        df['normalizedBugsFound'] = df['bugsFound'] / max_seeds

        pd.set_option('display.max_columns', None)  # Show all columns
        pd.set_option('display.width', 1000)       # Increase display width for better formatting

        # Group by 'model' and calculate statistics for each model
        model_stats = df.groupby('model').agg({
            # 'normalizedCoveredEdges': ['mean', 'sum', 'std'],
            # 'normalizedCoveredInstructions': ['mean', 'sum', 'std'],
            # 'normalizedBugsFound': ['mean', 'sum', 'std'],
            'coveredEdges': ['mean', 'sum', 'std'],
            'coveredInstructions': ['mean', 'sum', 'std'],
            'bugsFound': ['mean', 'sum', 'std']
        }).reset_index()

        # Display the statistics for each model
        print(model_stats)
        
        
        # Filter rows where any coverage field has a non-zero value
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Count the number of unique contracts for each model
        contracts_with_coverage = df_filtered.groupby('model')['contract'].nunique().sort_values(ascending=False)

        # Print the sorted list of models with the highest number of contracts with coverage
        print(contracts_with_coverage)        
        
        print("========================================")
        print("Model with most coveredEdges by contract")
        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Group by contract and find the best model based on coveredEdges
        best_models = df_filtered.groupby('contract').apply(
            lambda group: group.loc[group['coveredEdges'].idxmax()]
        )

        # Select only the relevant columns for the output (contract, best model, and coverage)
        best_models = best_models[['contract', 'model', 'coveredEdges']]

        # Sort by coveredEdges to display the best models first
        best_models = best_models.sort_values(by='coveredEdges', ascending=False)

        # Print the list of best models for each contract
        #print(best_models)        
        
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)        
        print(wins_count)                


        print("========================================")
        print("Model with most mean coveredEdges by contract")
        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Group by contract and model, and calculate the mean coveredEdges for each group
        mean_coverage = df_filtered.groupby(['contract', 'model']).agg(
            mean_coveredEdges=('coveredEdges', 'mean'),
            mean_coveredInstructions=('coveredInstructions', 'mean'),
            mean_coveredDefUseChains=('coveredDefUseChains', 'mean')
        ).reset_index()

        # For each contract, find the model with the highest mean coveredEdges
        best_models = mean_coverage.loc[mean_coverage.groupby('contract')['mean_coveredEdges'].idxmax()]

        # Count the number of wins (i.e., the number of times a model is the best for a contract)
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)

        # Print the sorted list of models by number of wins
        print(wins_count)                
        
        print("========================================")
        print("Model with most coveredInstructions by contract")
        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Group by contract and find the best model based on coveredEdges
        best_models = df_filtered.groupby('contract').apply(
            lambda group: group.loc[group['coveredInstructions'].idxmax()]
        )

        # Select only the relevant columns for the output (contract, best model, and coverage)
        best_models = best_models[['contract', 'model', 'coveredInstructions']]

        # Sort by coveredEdges to display the best models first
        best_models = best_models.sort_values(by='coveredInstructions', ascending=False)

        # Print the list of best models for each contract
        #print(best_models)        
        
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)        
        print(wins_count)                

        print("========================================")        
        print("Model with mean most coveredInstructions by contract")        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Group by contract and model, and calculate the mean coveredEdges for each group
        mean_coverage = df_filtered.groupby(['contract', 'model']).agg(
            mean_coveredEdges=('coveredEdges', 'mean'),
            mean_coveredInstructions=('coveredInstructions', 'mean'),
            mean_coveredDefUseChains=('coveredDefUseChains', 'mean')
        ).reset_index()

        # For each contract, find the model with the highest mean coveredEdges
        best_models = mean_coverage.loc[mean_coverage.groupby('contract')['mean_coveredInstructions'].idxmax()]

        # Count the number of wins (i.e., the number of times a model is the best for a contract)
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)

        # Print the sorted list of models by number of wins
        print(wins_count)                

        print("========================================")
        print("Model with most coveredDefUseChains by contract")
        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0)]

        # Group by contract and find the best model based on coveredEdges
        best_models = df_filtered.groupby('contract').apply(
            lambda group: group.loc[group['coveredDefUseChains'].idxmax()]
        )

        # Select only the relevant columns for the output (contract, best model, and coverage)
        best_models = best_models[['contract', 'model', 'coveredDefUseChains', 'temperature']]

        # Sort by coveredEdges to display the best models first
        best_models = best_models.sort_values(by='coveredDefUseChains', ascending=False)

        # Print the list of best models for each contract
        print(best_models)        
        
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)        
        print(wins_count)                
        print("========================================")


        print("========================================")
        print("Model with most bugsFound by contract")
        
        # Filter rows where coverage fields are greater than zero
        df_filtered = df[(df['coveredEdges'] > 0) | (df['coveredInstructions'] > 0) | (df['coveredDefUseChains'] > 0) | (df['bugsFound'] > 0)]

        # Group by contract and find the best model based on coveredEdges
        best_models = df_filtered.groupby('contract').apply(
            lambda group: group.loc[group['bugsFound'].idxmax()]
        )

        # Select only the relevant columns for the output (contract, best model, and coverage)
        best_models = best_models[['contract', 'model', 'bugsFound', 'temperature']]

        # Sort by coveredEdges to display the best models first
        best_models = best_models.sort_values(by='bugsFound', ascending=False)

        # Print the list of best models for each contract
        print(best_models)        
        
        wins_count = best_models['model'].value_counts()

        # Sort by number of wins (descending order)
        wins_count = wins_count.sort_values(ascending=False)        
        print(wins_count)                
        print("========================================")



        print("================THE BEST OF THE BEST========================")
        # Group by temperature and model
        grouped = df.groupby(['temperature', 'model'])

        # Initialize an empty list to store the results
        results = []

        # Iterate through each group
        for (temperature, model), group in grouped:
            # Calculate the mean of coverage metrics for this group
            mean_covered_edges = group['coveredEdges'].mean()
            mean_covered_instructions = group['coveredInstructions'].mean()
            mean_covered_def_use_chains = group['coveredDefUseChains'].mean()
            total_seeds = group['seed_file'].count()

            # Calculate a score for this model-temperature combination
            score = (mean_covered_edges + mean_covered_instructions + mean_covered_def_use_chains) * total_seeds
            results.append({
                'temperature': temperature,
                'model': model,
                'total_seeds': total_seeds,
                'mean_coveredEdges': mean_covered_edges,
                'mean_coveredInstructions': mean_covered_instructions,
                'mean_coveredDefUseChains': mean_covered_def_use_chains,
                'score': score
            })

        # Convert the results to a DataFrame
        results_df = pd.DataFrame(results)
        
        print(results_df.sort_values(by=['score'], ascending=False))
        # Get the best model and temperature combination overall (highest score)
        best_model_temperature = results_df.loc[results_df['score'].idxmax()]

        # Output the best model and temperature
        print(best_model_temperature)        
        print("================THE BEST OF THE BEST========================")        
        
        metrics = ['coveredEdges', 'coveredInstructions', 'coveredDefUseChains']
        print("\nANOVA Results:")
        for metric in metrics:
            # Group data by model for each metric
            groups = [df[df['model'] == model][metric] for model in df['model'].unique()]
            f_stat, p_value = f_oneway(*groups)
            print(f"Metric: {metric}")
            print(f"  F-statistic: {f_stat:.4f}, p-value: {p_value}")
            if p_value < 0.05:
                print("  Result: Statistically significant differences (p < 0.05)")
            else:
                print("  Result: No statistically significant differences (p >= 0.05)")        
        
        merged_df = (
            average_covered_instructions
            .merge(average_covered_edges, on=['model', 'temperature'])
            .merge(average_defusechain, on=['model', 'temperature'])
            .merge(average_bugsfound, on=['model', 'temperature'])
        )        
        plt.figure(figsize=(12, 8))

        for model in merged_df['model'].unique():
            model_data = merged_df[merged_df['model'] == model]

            # Plot each metric as a separate line
            plt.plot(
                model_data['temperature'],
                model_data['averageCoveredInstructions'],
                label=f'{model} - Avg Covered Instructions',
                linestyle='-', marker='o', linewidth=2
            )
            plt.plot(
                model_data['temperature'],
                model_data['averageCoveredEdges'],
                label=f'{model} - Avg Covered Edges',
                linestyle='--', marker='x', linewidth=2
            )
            plt.plot(
                model_data['temperature'],
                model_data['averageCoveredDefUseChains'],
                label=f'{model} - Avg DefUseChains',
                linestyle='-.', marker='s', linewidth=2
            )
            plt.plot(
                model_data['temperature'],
                model_data['averageBugsFound'],
                label=f'{model} - Avg Bugs Found',
                linestyle=':', marker='^', linewidth=2
            )

        # Labels, title, and legend
        plt.xlabel('Temperature', fontsize=14)
        plt.ylabel('Metrics', fontsize=14)
        plt.title('Metrics vs Temperature (Line Plot)', fontsize=16)
        plt.grid(alpha=0.3)
        plt.legend(fontsize=10, loc='upper right', bbox_to_anchor=(1.3, 1))

        # Adjust layout and show plot
        plt.tight_layout()
        plt.savefig('scatter_plot_coverage.png', dpi=300)
        
    def coverage2(self, csv):
        df = pd.read_csv(csv, header=None, names=self.COVERAGE_HEADER)
        
        # Group and calculate averages for each metric
        average_covered_instructions = df.groupby(['model', 'temperature'])['coveredInstructions'].mean().reset_index()
        average_covered_instructions.rename(columns={'coveredInstructions': 'averageCoveredInstructions'}, inplace=True)
        average_covered_instructions = average_covered_instructions.sort_values(by=['model', 'temperature'])

        average_covered_edges = df.groupby(['model', 'temperature'])['coveredEdges'].mean().reset_index()
        average_covered_edges.rename(columns={'coveredEdges': 'averageCoveredEdges'}, inplace=True)
        average_covered_edges = average_covered_edges.sort_values(by=['model', 'temperature'])

        average_defusechain = df.groupby(['model', 'temperature'])['coveredDefUseChains'].mean().reset_index()
        average_defusechain.rename(columns={'coveredDefUseChains': 'averageCoveredDefUseChains'}, inplace=True)
        average_defusechain = average_defusechain.sort_values(by=['model', 'temperature'])

        average_bugsfound = df.groupby(['model', 'temperature'])['bugsFound'].mean().reset_index()
        average_bugsfound.rename(columns={'bugsFound': 'averageBugsFound'}, inplace=True)
        average_bugsfound = average_bugsfound.sort_values(by=['model', 'temperature'])

        # Merge all metrics into a single data frame
        merged_df = (
            average_covered_instructions
            .merge(average_covered_edges, on=['model', 'temperature'])
            .merge(average_defusechain, on=['model', 'temperature'])
            .merge(average_bugsfound, on=['model', 'temperature'])
        )

        # Melt the data for Seaborn compatibility
        melted_df = merged_df.melt(
            id_vars=['model', 'temperature'],
            value_vars=['averageCoveredInstructions', 'averageCoveredEdges', 'averageCoveredDefUseChains', 'averageBugsFound'],
            var_name='Metric',
            value_name='Value'
        )

        # Create the FacetGrid with shared y-axis
        g = sns.FacetGrid(
            melted_df, 
            col='model', 
            col_wrap=3, 
            sharey=True,  # Ensure y-axis is shared across all facets
            height=4, 
            aspect=1.5
        )
        g.map(sns.lineplot, 'temperature', 'Value', 'Metric', marker='o')

        # Customize the plot
        g.add_legend(title='Metrics')
        g.set_axis_labels('Temperature', 'Value')
        g.set_titles('Model: {col_name}')
        plt.subplots_adjust(top=0.9)
        g.fig.suptitle('Metrics Trends by Model and Temperature (Uniform Y-Axis)')

        # Optional: Add grid lines for easier comparison
        for ax in g.axes.flat:
            ax.grid(alpha=0.3)

        plt.savefig('scatter_plot_coverage_2.png', dpi=800)        